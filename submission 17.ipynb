{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":59291,"databundleVersionId":6678907,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# improved feature engineering","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","editable":false}},{"cell_type":"markdown","source":"## importing the datasets needed for this analysis","metadata":{"editable":false}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom functools import reduce\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor, StackingRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom catboost import CatBoostRegressor\nfrom sklearn.preprocessing import StandardScaler, Normalizer\nfrom sklearn.model_selection import train_test_split\nfrom catboost import Pool, cv\nfrom collections import Counter\nfrom functools import reduce\nfrom tqdm import tqdm\nfrom itertools import cycle\nfrom scipy import stats\nfrom scipy.stats import skew, kurtosis\nfrom sklearn.decomposition import PCA\nimport seaborn as sns","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:42:40.172420Z","iopub.execute_input":"2023-11-30T06:42:40.172662Z","iopub.status.idle":"2023-11-30T06:42:42.537512Z","shell.execute_reply.started":"2023-11-30T06:42:40.172640Z","shell.execute_reply":"2023-11-30T06:42:42.536542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs=pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_logs.csv')\ntrain_scores=pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_scores.csv')\ntest_logs=pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/test_logs.csv')","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:42:42.539476Z","iopub.execute_input":"2023-11-30T06:42:42.539965Z","iopub.status.idle":"2023-11-30T06:42:57.012279Z","shell.execute_reply.started":"2023-11-30T06:42:42.539931Z","shell.execute_reply":"2023-11-30T06:42:57.011382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs.shape","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:42:57.013473Z","iopub.execute_input":"2023-11-30T06:42:57.013823Z","iopub.status.idle":"2023-11-30T06:42:57.021399Z","shell.execute_reply.started":"2023-11-30T06:42:57.013792Z","shell.execute_reply":"2023-11-30T06:42:57.020486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"My focus will be on the train logs dataset. It carries a lot of features that I think are important for this analyis.  but lets look at the train_scores first. ","metadata":{"editable":false}},{"cell_type":"code","source":"train_scores. describe()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:42:57.024293Z","iopub.execute_input":"2023-11-30T06:42:57.024880Z","iopub.status.idle":"2023-11-30T06:42:57.047619Z","shell.execute_reply.started":"2023-11-30T06:42:57.024828Z","shell.execute_reply":"2023-11-30T06:42:57.046757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the highest score was 6 and the lowest score was 0.500 with the average score being  3.7. Lets plot this in a histogram and see the results. ","metadata":{"editable":false}},{"cell_type":"code","source":"train_scores.score.hist()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:42:57.048657Z","iopub.execute_input":"2023-11-30T06:42:57.048985Z","iopub.status.idle":"2023-11-30T06:42:57.347679Z","shell.execute_reply.started":"2023-11-30T06:42:57.048956Z","shell.execute_reply":"2023-11-30T06:42:57.346752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We look at train_logs dataset and evaluate it. ","metadata":{"editable":false}},{"cell_type":"code","source":"train_logs.tail(20)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:42:57.348907Z","iopub.execute_input":"2023-11-30T06:42:57.349244Z","iopub.status.idle":"2023-11-30T06:42:57.368150Z","shell.execute_reply.started":"2023-11-30T06:42:57.349211Z","shell.execute_reply":"2023-11-30T06:42:57.367221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs[train_logs['id']=='001519c8']","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:42:57.369296Z","iopub.execute_input":"2023-11-30T06:42:57.369628Z","iopub.status.idle":"2023-11-30T06:42:58.718638Z","shell.execute_reply.started":"2023-11-30T06:42:57.369596Z","shell.execute_reply":"2023-11-30T06:42:58.717738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_logs.down_event.value_counts())","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:42:58.720261Z","iopub.execute_input":"2023-11-30T06:42:58.720715Z","iopub.status.idle":"2023-11-30T06:42:59.781452Z","shell.execute_reply.started":"2023-11-30T06:42:58.720661Z","shell.execute_reply":"2023-11-30T06:42:59.780207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs.up_event.value_counts()[:100]","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:42:59.782802Z","iopub.execute_input":"2023-11-30T06:42:59.783063Z","iopub.status.idle":"2023-11-30T06:43:00.828060Z","shell.execute_reply.started":"2023-11-30T06:42:59.783040Z","shell.execute_reply":"2023-11-30T06:43:00.826914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs.text_change.value_counts()\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:00.832989Z","iopub.execute_input":"2023-11-30T06:43:00.833856Z","iopub.status.idle":"2023-11-30T06:43:01.800132Z","shell.execute_reply.started":"2023-11-30T06:43:00.833824Z","shell.execute_reply":"2023-11-30T06:43:01.798944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs.id.value_counts()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:01.801313Z","iopub.execute_input":"2023-11-30T06:43:01.801597Z","iopub.status.idle":"2023-11-30T06:43:02.755860Z","shell.execute_reply.started":"2023-11-30T06:43:01.801572Z","shell.execute_reply":"2023-11-30T06:43:02.754725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs.cursor_position.describe().round(2)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:02.757266Z","iopub.execute_input":"2023-11-30T06:43:02.757578Z","iopub.status.idle":"2023-11-30T06:43:02.939444Z","shell.execute_reply.started":"2023-11-30T06:43:02.757553Z","shell.execute_reply":"2023-11-30T06:43:02.938550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs.event_id.describe().round(2)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:02.940788Z","iopub.execute_input":"2023-11-30T06:43:02.941142Z","iopub.status.idle":"2023-11-30T06:43:03.113155Z","shell.execute_reply.started":"2023-11-30T06:43:02.941108Z","shell.execute_reply":"2023-11-30T06:43:03.112113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs.event_id.hist()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:03.114235Z","iopub.execute_input":"2023-11-30T06:43:03.114508Z","iopub.status.idle":"2023-11-30T06:43:03.526714Z","shell.execute_reply.started":"2023-11-30T06:43:03.114484Z","shell.execute_reply":"2023-11-30T06:43:03.525670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs['activity'].value_counts()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:03.527990Z","iopub.execute_input":"2023-11-30T06:43:03.528331Z","iopub.status.idle":"2023-11-30T06:43:04.769192Z","shell.execute_reply.started":"2023-11-30T06:43:03.528300Z","shell.execute_reply":"2023-11-30T06:43:04.768185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature engineering","metadata":{"editable":false}},{"cell_type":"code","source":"def get_flights(df):\n    return df['down_time'].shift(-1) - df['up_time']\n\ndef flight_time(data):\n    means = []\n    stds = []\n    mins = []\n    maxs = []\n    medians = []\n\n    grouped_data = data.groupby('id')\n\n    for _, df in tqdm(grouped_data):\n        flight_times = get_flights(df)\n        mean_time = np.mean(flight_times)\n        std_time = np.std(flight_times)\n        min_time = np.min(flight_times)\n        max_time = np.max(flight_times)\n        median_time = np.median(flight_times)\n\n        means.append(mean_time)\n        stds.append(std_time)\n        mins.append(min_time)\n        maxs.append(max_time)\n       \n\n    DF = pd.DataFrame({\n        'id': grouped_data.groups.keys(),\n        \"mean flight time\": means,\n        'std flight time': stds,\n        'minimum flight time': mins,\n        'maximum flight time': maxs\n    })\n\n    return DF","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:04.770560Z","iopub.execute_input":"2023-11-30T06:43:04.771236Z","iopub.status.idle":"2023-11-30T06:43:04.779738Z","shell.execute_reply.started":"2023-11-30T06:43:04.771198Z","shell.execute_reply":"2023-11-30T06:43:04.778736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=flight_time(train_logs)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:04.780894Z","iopub.execute_input":"2023-11-30T06:43:04.781234Z","iopub.status.idle":"2023-11-30T06:43:09.912928Z","shell.execute_reply.started":"2023-11-30T06:43:04.781204Z","shell.execute_reply":"2023-11-30T06:43:09.912066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:09.914249Z","iopub.execute_input":"2023-11-30T06:43:09.914632Z","iopub.status.idle":"2023-11-30T06:43:09.927327Z","shell.execute_reply.started":"2023-11-30T06:43:09.914599Z","shell.execute_reply":"2023-11-30T06:43:09.926143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get the total time spent on a the essay\ndef time_spent(data):\n    data=data[['id', 'action_time']]\n    mean_time=data.groupby('id').mean()\n    return mean_time\n    ","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:09.928756Z","iopub.execute_input":"2023-11-30T06:43:09.929020Z","iopub.status.idle":"2023-11-30T06:43:09.939506Z","shell.execute_reply.started":"2023-11-30T06:43:09.928997Z","shell.execute_reply":"2023-11-30T06:43:09.938619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"times=time_spent(train_logs)\ntimes.reset_index(inplace=True)\ntimes\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:09.940568Z","iopub.execute_input":"2023-11-30T06:43:09.941272Z","iopub.status.idle":"2023-11-30T06:43:10.949128Z","shell.execute_reply.started":"2023-11-30T06:43:09.941242Z","shell.execute_reply":"2023-11-30T06:43:10.948159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actions = pd.DataFrame({\n    'actions': train_logs['id'].value_counts()\n})\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:10.950154Z","iopub.execute_input":"2023-11-30T06:43:10.950441Z","iopub.status.idle":"2023-11-30T06:43:11.858184Z","shell.execute_reply.started":"2023-11-30T06:43:10.950416Z","shell.execute_reply":"2023-11-30T06:43:11.857120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actions.reset_index(inplace=True)\nactions\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:11.859535Z","iopub.execute_input":"2023-11-30T06:43:11.859914Z","iopub.status.idle":"2023-11-30T06:43:11.874289Z","shell.execute_reply.started":"2023-11-30T06:43:11.859883Z","shell.execute_reply":"2023-11-30T06:43:11.873438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pause measures\ndef pauses(data):\n\n    Nonproduction=data[data['activity']=='Nonproduction']\n    No_pauses=Nonproduction.id.value_counts()\n    return No_pauses\npauses_count=pauses(train_logs)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:11.875473Z","iopub.execute_input":"2023-11-30T06:43:11.875818Z","iopub.status.idle":"2023-11-30T06:43:13.294766Z","shell.execute_reply.started":"2023-11-30T06:43:11.875785Z","shell.execute_reply":"2023-11-30T06:43:13.293721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pauses_count","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:13.296071Z","iopub.execute_input":"2023-11-30T06:43:13.296497Z","iopub.status.idle":"2023-11-30T06:43:13.304732Z","shell.execute_reply.started":"2023-11-30T06:43:13.296459Z","shell.execute_reply":"2023-11-30T06:43:13.303804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pauses_count = pd.DataFrame({\n    'pauses': pauses(train_logs)\n})\npauses_count.reset_index(inplace=True)\npauses_count\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:13.306178Z","iopub.execute_input":"2023-11-30T06:43:13.306588Z","iopub.status.idle":"2023-11-30T06:43:14.745209Z","shell.execute_reply.started":"2023-11-30T06:43:13.306549Z","shell.execute_reply":"2023-11-30T06:43:14.744189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# backspace count\ndef backspace_count(data):\n    Backspace=data[data['up_event']=='Backspace']\n    return Backspace.id.value_counts()\nbackspace=backspace_count(train_logs)\n\nbackspace = pd.DataFrame({\n    'backspace': backspace_count(train_logs)\n})\nbackspace.reset_index(inplace=True)\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:14.746801Z","iopub.execute_input":"2023-11-30T06:43:14.747253Z","iopub.status.idle":"2023-11-30T06:43:17.698734Z","shell.execute_reply.started":"2023-11-30T06:43:14.747213Z","shell.execute_reply":"2023-11-30T06:43:17.697742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"backspace","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:17.699955Z","iopub.execute_input":"2023-11-30T06:43:17.700236Z","iopub.status.idle":"2023-11-30T06:43:17.711436Z","shell.execute_reply.started":"2023-11-30T06:43:17.700213Z","shell.execute_reply":"2023-11-30T06:43:17.710495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"backspace","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:17.718595Z","iopub.execute_input":"2023-11-30T06:43:17.718910Z","iopub.status.idle":"2023-11-30T06:43:17.729995Z","shell.execute_reply.started":"2023-11-30T06:43:17.718884Z","shell.execute_reply":"2023-11-30T06:43:17.729042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# words per minute- I omit the  non production\ndef words_per_minute(data):\n    production=data[data['activity']!='Nonproduction']\n    # getting total minutes in active production\n    production_active=production[['id', 'action_time']]\n    total_minutes=production_active.groupby('id').sum()['action_time']/60000\n    # getting the total words\n    words_df=production[['id', 'word_count']]\n    words=words_df.groupby('id').max()['word_count']\n    return words/total_minutes\n    ","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:17.731100Z","iopub.execute_input":"2023-11-30T06:43:17.731353Z","iopub.status.idle":"2023-11-30T06:43:17.739860Z","shell.execute_reply.started":"2023-11-30T06:43:17.731331Z","shell.execute_reply":"2023-11-30T06:43:17.739094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def keystrokes_per_minute(data):\n    production=data[data['activity']=='Input']\n    production_active=production[['id', 'action_time']]\n    total_minutes=production_active.groupby('id').sum()['action_time']/60000\n    strokes_df=production[['id', 'down_event']]\n    strokes=strokes_df.groupby('id').count()['down_event']\n    return strokes/total_minutes\n\nkeystrokes = pd.DataFrame({\n    'keystrokes_per_minute': keystrokes_per_minute(train_logs)\n})\nkeystrokes.reset_index(inplace=True)\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:17.740780Z","iopub.execute_input":"2023-11-30T06:43:17.741010Z","iopub.status.idle":"2023-11-30T06:43:21.952400Z","shell.execute_reply.started":"2023-11-30T06:43:17.740990Z","shell.execute_reply":"2023-11-30T06:43:21.951592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pastes(data):\n    pastes=data[data['activity']=='Paste']\n    df=pastes[['id', 'activity']]\n    return df.groupby('id').count()['activity']\npaste_text= pd.DataFrame({\n    'paste_text': pastes(train_logs)\n})\npaste_text.reset_index(inplace=True)\nkeystrokes = pd.DataFrame({\n    'keystrokes_per_minute': keystrokes_per_minute(train_logs)\n})\nkeystrokes.reset_index(inplace=True)\ntyping_speed = pd.DataFrame({\n    'typing_speed': words_per_minute(train_logs)\n})\ntyping_speed.reset_index(inplace=True)\n\nbackspace=backspace_count(train_logs)\n\nbackspace = pd.DataFrame({\n    'backspace': backspace_count(train_logs)\n})\nbackspace.reset_index(inplace=True)\n\npauses_count = pd.DataFrame({\n    'pauses': pauses(train_logs)\n})\npauses_count.reset_index(inplace=True)\n\n\n\ntimes=time_spent(train_logs)\ntimes.reset_index(inplace=True)\n\ndf=flight_time(train_logs)\nactions = pd.DataFrame({\n    'actions': train_logs['id'].value_counts()\n})\nactions.reset_index(inplace=True)\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:21.953529Z","iopub.execute_input":"2023-11-30T06:43:21.953826Z","iopub.status.idle":"2023-11-30T06:43:42.696294Z","shell.execute_reply.started":"2023-11-30T06:43:21.953801Z","shell.execute_reply":"2023-11-30T06:43:42.695496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cut_text(data):\n    cuts=data[data['activity']=='Remove/Cut']\n    df=cuts[['id', 'activity']]\n    return df.groupby('id').count()['activity']\ncut_text(train_logs)\n\ncuts= pd.DataFrame({\n    'cut_text': cut_text(train_logs)\n})\ncuts.reset_index(inplace=True)\npaste_text= pd.DataFrame({\n    'paste_text': pastes(train_logs)\n})\npaste_text.reset_index(inplace=True)\nkeystrokes = pd.DataFrame({\n    'keystrokes_per_minute': keystrokes_per_minute(train_logs)\n})\nkeystrokes.reset_index(inplace=True)\ntyping_speed = pd.DataFrame({\n    'typing_speed': words_per_minute(train_logs)\n})\ntyping_speed.reset_index(inplace=True)\n\nbackspace=backspace_count(train_logs)\n\nbackspace = pd.DataFrame({\n    'backspace': backspace_count(train_logs)\n})\nbackspace.reset_index(inplace=True)\n\npauses_count = pd.DataFrame({\n    'pauses': pauses(train_logs)\n})\npauses_count.reset_index(inplace=True)\n\n\n\ntimes=time_spent(train_logs)\ntimes.reset_index(inplace=True)\n\ndf=flight_time(train_logs)\nactions = pd.DataFrame({\n    'actions': train_logs['id'].value_counts()\n})\nactions.reset_index(inplace=True)\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:43:42.697332Z","iopub.execute_input":"2023-11-30T06:43:42.697582Z","iopub.status.idle":"2023-11-30T06:44:06.655038Z","shell.execute_reply.started":"2023-11-30T06:43:42.697560Z","shell.execute_reply":"2023-11-30T06:44:06.654237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def replace_text(data):\n    replaces=data[data['activity']=='Replace']\n    df=replaces[['id', 'activity']]\n    return df.groupby('id').count()['activity']\nreplace_text(train_logs)\n\n\n\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:06.656236Z","iopub.execute_input":"2023-11-30T06:44:06.656581Z","iopub.status.idle":"2023-11-30T06:44:07.835511Z","shell.execute_reply.started":"2023-11-30T06:44:06.656545Z","shell.execute_reply":"2023-11-30T06:44:07.834679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get punctuations\nimport string\n\ndef is_punctuation_only(cell_value):\n    return all(char in string.punctuation for char in cell_value)\n\ntrain_logs['is_punctuation_only'] = train_logs['text_change'].apply(is_punctuation_only)\n\npunctuation_counts = train_logs.groupby('id')['is_punctuation_only'].sum().reset_index()\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:07.836466Z","iopub.execute_input":"2023-11-30T06:44:07.836746Z","iopub.status.idle":"2023-11-30T06:44:17.958693Z","shell.execute_reply.started":"2023-11-30T06:44:07.836717Z","shell.execute_reply":"2023-11-30T06:44:17.957906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"punctuation_counts","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:17.959763Z","iopub.execute_input":"2023-11-30T06:44:17.960026Z","iopub.status.idle":"2023-11-30T06:44:17.970805Z","shell.execute_reply.started":"2023-11-30T06:44:17.960003Z","shell.execute_reply":"2023-11-30T06:44:17.969746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input counts\ndef input_counts(data):\n    data = data[['id', 'activity','text_change']]\n    input_occurrences = data[data['activity'] == 'Input'].groupby('id')['text_change'].count().reset_index()\n    return input_occurrences","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:17.972125Z","iopub.execute_input":"2023-11-30T06:44:17.972501Z","iopub.status.idle":"2023-11-30T06:44:17.980521Z","shell.execute_reply.started":"2023-11-30T06:44:17.972465Z","shell.execute_reply":"2023-11-30T06:44:17.979657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_counts(train_logs)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:17.981781Z","iopub.execute_input":"2023-11-30T06:44:17.982100Z","iopub.status.idle":"2023-11-30T06:44:21.243510Z","shell.execute_reply.started":"2023-11-30T06:44:17.982060Z","shell.execute_reply":"2023-11-30T06:44:21.242390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ninputs= input_counts(train_logs)\n\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:21.244529Z","iopub.execute_input":"2023-11-30T06:44:21.244814Z","iopub.status.idle":"2023-11-30T06:44:24.493736Z","shell.execute_reply.started":"2023-11-30T06:44:21.244782Z","shell.execute_reply":"2023-11-30T06:44:24.492807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# determine the characters that were replaced\n# first lets view the data\ntrain_logs[train_logs['activity']=='Replace']","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:24.494815Z","iopub.execute_input":"2023-11-30T06:44:24.495094Z","iopub.status.idle":"2023-11-30T06:44:25.682683Z","shell.execute_reply.started":"2023-11-30T06:44:24.495070Z","shell.execute_reply":"2023-11-30T06:44:25.681811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\ndef change_count(data):\n    replace_data = data[data['activity'] == 'Replace']\n    splits = replace_data['text_change'].str.split('=>')\n    \n    replaced = splits.apply(lambda x: len(x[0]))\n    changed = splits.apply(lambda x: len(x[1]))\n\n    sum_replaced = replaced.sum()\n    sum_changed = changed.sum()\n    average_replaced = replaced.mean()\n    average_changed = changed.mean()\n\n    return sum_replaced, sum_changed, average_replaced, average_changed\n\ndef counts_of_changes(data):\n    sum_replace = []\n    sum_change = []\n    average_replace = []\n\n    for i in tqdm(data['id'].unique(), desc='Processing IDs'):\n        new_data = data[data['id'] == i]\n        (\n            sum_replaced,\n            sum_changed,\n            average_replaced,\n            average_changed\n        ) = change_count(new_data)\n\n        sum_replace.append(sum_replaced)\n        sum_change.append(sum_changed)\n        average_replace.append(average_replaced)\n\n    result_df = pd.DataFrame({\n        'id': data['id'].unique(),\n        'sum_replace': sum_replace,\n        'sum_change': sum_change,\n        'average_replace': average_replace,\n        'average_changed': average_changed\n    })\n\n    return result_df\n\n\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:25.684031Z","iopub.execute_input":"2023-11-30T06:44:25.684333Z","iopub.status.idle":"2023-11-30T06:44:25.694557Z","shell.execute_reply.started":"2023-11-30T06:44:25.684307Z","shell.execute_reply":"2023-11-30T06:44:25.693524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Preprocessor:\n    \n    def __init__(self, seed):\n        self.seed = seed\n        \n        self.activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n        self.events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', \n              'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n        self.text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n        self.punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/',\n                        '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+']\n        self.gaps = [1, 2, 3, 5, 10, 20, 50, 100]\n#         self.gaps = [1, 2]\n    \n    def activity_counts(self, df):\n        tmp_df = df.groupby('id').agg({'activity': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['activity'].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.activities:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n        return ret\n\n\n    def event_counts(self, df, colname):\n        tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df[colname].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.events:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n        return ret\n\n\n    def text_change_counts(self, df):\n        tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['text_change'].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.text_changes:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n        return ret\n\n    def match_punctuations(self, df):\n        tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['down_event'].values):\n            cnt = 0\n            items = list(Counter(li).items())\n            for item in items:\n                k, v = item[0], item[1]\n                if k in self.punctuations:\n                    cnt += v\n            ret.append(cnt)\n        ret = pd.DataFrame({'punct_cnt': ret})\n        return ret\n\n\n    def get_input_words(self, df):\n        tmp_df = df[(~df['text_change'].str.contains('=>'))&(df['text_change'] != 'NoChange')].reset_index(drop=True)\n        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: ''.join(x))\n        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: re.findall(r'q+', x))\n        tmp_df['input_word_count'] = tmp_df['text_change'].apply(len)\n        tmp_df['input_word_length_mean'] = tmp_df['text_change'].apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df['input_word_length_max'] = tmp_df['text_change'].apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df['input_word_length_std'] = tmp_df['text_change'].apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df.drop(['text_change'], axis=1, inplace=True)\n        return tmp_df\n    \n    def make_feats(self, df):\n        \n        print(\"Starting to engineer features\")\n        \n        # initialize features dataframe\n        feats = pd.DataFrame({'id': df['id'].unique().tolist()})\n        \n        # get shifted features\n        # time shift\n        print(\"Engineering time data\")\n        for gap in self.gaps:\n            print(f\"> for gap {gap}\")\n            df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap)\n            df[f'action_time_gap{gap}'] = df['down_time'] - df[f'up_time_shift{gap}']\n        df.drop(columns=[f'up_time_shift{gap}' for gap in self.gaps], inplace=True)\n\n        # cursor position shift\n        print(\"Engineering cursor position data\")\n        for gap in self.gaps:\n            print(f\"> for gap {gap}\")\n            df[f'cursor_position_shift{gap}'] = df.groupby('id')['cursor_position'].shift(gap)\n            df[f'cursor_position_change{gap}'] = df['cursor_position'] - df[f'cursor_position_shift{gap}']\n            df[f'cursor_position_abs_change{gap}'] = np.abs(df[f'cursor_position_change{gap}'])\n        df.drop(columns=[f'cursor_position_shift{gap}' for gap in self.gaps], inplace=True)\n\n        # word count shift\n        print(\"Engineering word count data\")\n        for gap in self.gaps:\n            print(f\"> for gap {gap}\")\n            df[f'word_count_shift{gap}'] = df.groupby('id')['word_count'].shift(gap)\n            df[f'word_count_change{gap}'] = df['word_count'] - df[f'word_count_shift{gap}']\n            df[f'word_count_abs_change{gap}'] = np.abs(df[f'word_count_change{gap}'])\n        df.drop(columns=[f'word_count_shift{gap}' for gap in self.gaps], inplace=True)\n        \n        # get aggregate statistical features\n        print(\"Engineering statistical summaries for features\")\n        # [(feature name, [ stat summaries to add ])]\n        feats_stat = [\n            ('event_id', ['max']),\n            ('up_time', ['max']),\n            ('action_time', ['sum', 'max', 'mean', 'std']),\n            ('activity', ['nunique']),\n            ('down_event', ['nunique']),\n            ('up_event', ['nunique']),\n            ('text_change', ['nunique']),\n            ('cursor_position', ['nunique', 'max', 'mean']),\n            ('word_count', ['nunique', 'max', 'mean'])]\n        for gap in self.gaps:\n            feats_stat.extend([\n                (f'action_time_gap{gap}', ['max', 'min', 'mean', 'std', 'sum', skew, kurtosis]),\n                (f'cursor_position_change{gap}', ['max', 'mean', 'std', 'sum', skew, kurtosis]),\n                (f'word_count_change{gap}', ['max', 'mean', 'std', 'sum', skew, kurtosis])\n            ])\n        \n        pbar = tqdm(feats_stat)\n        for item in pbar:\n            colname, methods = item[0], item[1]\n            for method in methods:\n                pbar.set_postfix()\n                if isinstance(method, str):\n                    method_name = method\n                else:\n                    method_name = method.__name__\n                    \n                pbar.set_postfix(column=colname, method=method_name)\n                tmp_df = df.groupby(['id']).agg({colname: method}).reset_index().rename(columns={colname: f'{colname}_{method_name}'})\n                feats = feats.merge(tmp_df, on='id', how='left')\n\n        # counts\n        print(\"Engineering activity counts data\")\n        tmp_df = self.activity_counts(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering event counts data\")\n        tmp_df = self.event_counts(df, 'down_event')\n        feats = pd.concat([feats, tmp_df], axis=1)\n        tmp_df = self.event_counts(df, 'up_event')\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering text change counts data\")\n        tmp_df = self.text_change_counts(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering punctuation counts data\")\n        tmp_df = self.match_punctuations(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n\n        # input words\n        print(\"Engineering input words data\")\n        tmp_df = self.get_input_words(df)\n        feats = pd.merge(feats, tmp_df, on='id', how='left')\n\n        # compare feats\n        print(\"Engineering ratios data\")\n        feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n        feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n        feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n        feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n        \n        print(\"Done!\")\n        return feats","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:25.695895Z","iopub.execute_input":"2023-11-30T06:44:25.696174Z","iopub.status.idle":"2023-11-30T06:44:25.739840Z","shell.execute_reply.started":"2023-11-30T06:44:25.696150Z","shell.execute_reply":"2023-11-30T06:44:25.738925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_func(train_logs):\n    inputs= input_counts(train_logs)\n    train_logs['is_punctuation_only'] = train_logs['text_change'].apply(is_punctuation_only)\n\n    punctuation_counts = train_logs.groupby('id')['is_punctuation_only'].sum().reset_index()\n    replaced= pd.DataFrame({\n        'replaced_text': replace_text(train_logs)\n    })\n    replaced.reset_index(inplace=True)\n    cuts= pd.DataFrame({\n        'cut_text': cut_text(train_logs)\n    })\n    cuts.reset_index(inplace=True)\n    paste_text= pd.DataFrame({\n        'paste_text': pastes(train_logs)\n    })\n    paste_text.reset_index(inplace=True)\n    keystrokes = pd.DataFrame({\n        'keystrokes_per_minute': keystrokes_per_minute(train_logs)\n    })\n    keystrokes.reset_index(inplace=True)\n    typing_speed = pd.DataFrame({\n        'typing_speed': words_per_minute(train_logs)\n    })\n    typing_speed.reset_index(inplace=True)\n\n    backspace=backspace_count(train_logs)\n\n    backspace = pd.DataFrame({\n        'backspace': backspace_count(train_logs)\n    })\n    backspace.reset_index(inplace=True)\n\n    pauses_count = pd.DataFrame({\n        'pauses': pauses(train_logs)\n    })\n    pauses_count.reset_index(inplace=True)\n\n\n\n    times=time_spent(train_logs)\n    times.reset_index(inplace=True)\n\n    df=flight_time(train_logs)\n    actions = pd.DataFrame({\n        'actions': train_logs['id'].value_counts()\n    })\n    actions.reset_index(inplace=True)\n    preprocessor = Preprocessor(seed=42)\n\n    print(\"Engineering features for training data\")\n\n    train_feats = preprocessor.make_feats(train_logs)\n    train_agg_fe_df = train_logs.groupby(\"id\")[['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']].agg(['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum'])\n    train_agg_fe_df.columns = ['_'.join(x) for x in train_agg_fe_df.columns]\n    train_agg_fe_df = train_agg_fe_df.add_prefix(\"tmp_\")\n    train_agg_fe_df.reset_index(inplace=True)\n    df_list=[ inputs, punctuation_counts,\n        replaced, cuts, paste_text, keystrokes, typing_speed,\n              backspace, pauses_count, times, df, actions, train_agg_fe_df\n    ]\n    df_merged= reduce(lambda  left,right: pd.merge(left,right,on=['id'],\n                                            how='outer'), df_list)\n    return df_merged","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:25.740753Z","iopub.execute_input":"2023-11-30T06:44:25.741035Z","iopub.status.idle":"2023-11-30T06:44:25.754835Z","shell.execute_reply.started":"2023-11-30T06:44:25.741012Z","shell.execute_reply":"2023-11-30T06:44:25.754052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_merged=data_func(train_logs)\ndf_merged=pd.merge(df_merged, train_scores, on=['id'],\n                                               how='outer')\ndf_merged.fillna(0, inplace=True)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:44:25.755886Z","iopub.execute_input":"2023-11-30T06:44:25.756136Z","iopub.status.idle":"2023-11-30T06:49:08.591550Z","shell.execute_reply.started":"2023-11-30T06:44:25.756114Z","shell.execute_reply":"2023-11-30T06:49:08.590726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_merged.columns","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:49:08.592626Z","iopub.execute_input":"2023-11-30T06:49:08.592951Z","iopub.status.idle":"2023-11-30T06:49:08.599655Z","shell.execute_reply.started":"2023-11-30T06:49:08.592925Z","shell.execute_reply":"2023-11-30T06:49:08.598744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trimm_correlated(df_in, threshold):\n    df_corr = df_in.corr(method='pearson', min_periods=1)\n    df_not_correlated = ~(df_corr.mask(np.tril(np.ones([len(df_corr)]*2, dtype=bool))).abs() > threshold).any()\n    un_corr_idx = df_not_correlated.loc[df_not_correlated[df_not_correlated.index] == True].index\n    df_out = df_in[un_corr_idx]\n    return df_out\n\ndf= df_merged.drop('id', axis=1)\ndf=trimm_correlated(df, 0.8)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:49:08.600900Z","iopub.execute_input":"2023-11-30T06:49:08.601215Z","iopub.status.idle":"2023-11-30T06:49:08.639861Z","shell.execute_reply.started":"2023-11-30T06:49:08.601191Z","shell.execute_reply":"2023-11-30T06:49:08.639175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data splitting","metadata":{"editable":false}},{"cell_type":"code","source":"X=df.drop('score', axis=1)\ny=df['score']","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:49:08.640773Z","iopub.execute_input":"2023-11-30T06:49:08.641025Z","iopub.status.idle":"2023-11-30T06:49:08.645999Z","shell.execute_reply.started":"2023-11-30T06:49:08.641003Z","shell.execute_reply":"2023-11-30T06:49:08.645076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal=Normalizer()\nX_Normalized=normal.fit_transform(X)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:49:08.647261Z","iopub.execute_input":"2023-11-30T06:49:08.647922Z","iopub.status.idle":"2023-11-30T06:49:08.658351Z","shell.execute_reply.started":"2023-11-30T06:49:08.647886Z","shell.execute_reply":"2023-11-30T06:49:08.657463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test=train_test_split(X_Normalized,y, test_size=0.2, random_state=42)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:49:08.659595Z","iopub.execute_input":"2023-11-30T06:49:08.659970Z","iopub.status.idle":"2023-11-30T06:49:08.666350Z","shell.execute_reply.started":"2023-11-30T06:49:08.659917Z","shell.execute_reply":"2023-11-30T06:49:08.665476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=GradientBoostingRegressor()\nmodel.fit(X_train, y_train)\ny_preds=model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_preds))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:49:08.667434Z","iopub.execute_input":"2023-11-30T06:49:08.667783Z","iopub.status.idle":"2023-11-30T06:49:09.773204Z","shell.execute_reply.started":"2023-11-30T06:49:08.667757Z","shell.execute_reply":"2023-11-30T06:49:09.772355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the base models\nbase_models = [\n    ('catboost', CatBoostRegressor()),\n    ('cat',CatBoostRegressor()),\n    ('RF',RandomForestRegressor(n_estimators=500)),\n    ('xgb',XGBRegressor(n_estimators=200)),\n    ('xgb2',XGBRegressor()),\n    ('cat2',CatBoostRegressor())\n]\n# Define the final estimator\nfinal_estimator = SVR()  \n# Create the stacking regressor\nstacking_regressor = StackingRegressor(\n    estimators=base_models,\n    final_estimator=final_estimator\n)\n# Fit the stacking regressor with your training data\nstacking_regressor.fit(X_train, y_train)\n","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:49:09.774332Z","iopub.execute_input":"2023-11-30T06:49:09.774583Z","iopub.status.idle":"2023-11-30T06:51:13.508557Z","shell.execute_reply.started":"2023-11-30T06:49:09.774561Z","shell.execute_reply":"2023-11-30T06:51:13.507631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = stacking_regressor.predict(X_test )\nnp.sqrt(mean_squared_error(y_test, y_pred))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:51:13.510017Z","iopub.execute_input":"2023-11-30T06:51:13.510370Z","iopub.status.idle":"2023-11-30T06:51:13.649337Z","shell.execute_reply.started":"2023-11-30T06:51:13.510337Z","shell.execute_reply":"2023-11-30T06:51:13.648440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_agg_fe_df = test_logs.groupby(\"id\")[['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']].agg(['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum'])\ntest_agg_fe_df.columns = ['_'.join(x) for x in test_agg_fe_df.columns]\ntest_agg_fe_df = test_agg_fe_df.add_prefix(\"tmp_\")\ntest_agg_fe_df.reset_index(inplace=True)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:51:13.650431Z","iopub.execute_input":"2023-11-30T06:51:13.650727Z","iopub.status.idle":"2023-11-30T06:51:13.679040Z","shell.execute_reply.started":"2023-11-30T06:51:13.650680Z","shell.execute_reply":"2023-11-30T06:51:13.678095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_logs.shape","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:51:13.680326Z","iopub.execute_input":"2023-11-30T06:51:13.680639Z","iopub.status.idle":"2023-11-30T06:51:13.687322Z","shell.execute_reply.started":"2023-11-30T06:51:13.680615Z","shell.execute_reply":"2023-11-30T06:51:13.686384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=data_func(test_logs)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:51:13.688365Z","iopub.execute_input":"2023-11-30T06:51:13.688624Z","iopub.status.idle":"2023-11-30T06:51:14.983354Z","shell.execute_reply.started":"2023-11-30T06:51:13.688602Z","shell.execute_reply":"2023-11-30T06:51:14.982497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest.fillna(0, inplace=True)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:51:14.984439Z","iopub.execute_input":"2023-11-30T06:51:14.984745Z","iopub.status.idle":"2023-11-30T06:51:14.989702Z","shell.execute_reply.started":"2023-11-30T06:51:14.984713Z","shell.execute_reply":"2023-11-30T06:51:14.988583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:51:14.991074Z","iopub.execute_input":"2023-11-30T06:51:14.991409Z","iopub.status.idle":"2023-11-30T06:51:15.000990Z","shell.execute_reply.started":"2023-11-30T06:51:14.991378Z","shell.execute_reply":"2023-11-30T06:51:15.000092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=stacking_regressor.predict(test.drop('id', axis=1))\npreds","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:51:15.002103Z","iopub.execute_input":"2023-11-30T06:51:15.002929Z","iopub.status.idle":"2023-11-30T06:51:15.834427Z","shell.execute_reply.started":"2023-11-30T06:51:15.002903Z","shell.execute_reply":"2023-11-30T06:51:15.833039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.DataFrame({'id':test_logs.id.unique(), 'score':preds})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2023-11-30T06:51:15.835291Z","iopub.status.idle":"2023-11-30T06:51:15.835741Z","shell.execute_reply.started":"2023-11-30T06:51:15.835504Z","shell.execute_reply":"2023-11-30T06:51:15.835525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}